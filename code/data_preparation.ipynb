{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n0            842     0          2.2         0   1       0           7    0.6   \n1           1021     1          0.5         1   0       1          53    0.7   \n2            563     1          0.5         1   2       1          41    0.9   \n3            615     1          2.5         0   0       0          10    0.8   \n4           1821     1          1.2         0  13       1          44    0.6   \n\n   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n0        188        2  ...         20       756  2549     9     7         19   \n1        136        3  ...        905      1988  2631    17     3          7   \n2        145        5  ...       1263      1716  2603    11     2          9   \n3        131        6  ...       1216      1786  2769    16     8         11   \n4        141        2  ...       1208      1212  1411     8     2         15   \n\n   three_g  touch_screen  wifi  price_range  \n0        0             0     1            1  \n1        1             1     0            2  \n2        1             1     0            2  \n3        1             0     0            2  \n4        1             1     0            1  \n\n[5 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>battery_power</th>\n      <th>blue</th>\n      <th>clock_speed</th>\n      <th>dual_sim</th>\n      <th>fc</th>\n      <th>four_g</th>\n      <th>int_memory</th>\n      <th>m_dep</th>\n      <th>mobile_wt</th>\n      <th>n_cores</th>\n      <th>...</th>\n      <th>px_height</th>\n      <th>px_width</th>\n      <th>ram</th>\n      <th>sc_h</th>\n      <th>sc_w</th>\n      <th>talk_time</th>\n      <th>three_g</th>\n      <th>touch_screen</th>\n      <th>wifi</th>\n      <th>price_range</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842</td>\n      <td>0</td>\n      <td>2.2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0.6</td>\n      <td>188</td>\n      <td>2</td>\n      <td>...</td>\n      <td>20</td>\n      <td>756</td>\n      <td>2549</td>\n      <td>9</td>\n      <td>7</td>\n      <td>19</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1021</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>53</td>\n      <td>0.7</td>\n      <td>136</td>\n      <td>3</td>\n      <td>...</td>\n      <td>905</td>\n      <td>1988</td>\n      <td>2631</td>\n      <td>17</td>\n      <td>3</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>563</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>41</td>\n      <td>0.9</td>\n      <td>145</td>\n      <td>5</td>\n      <td>...</td>\n      <td>1263</td>\n      <td>1716</td>\n      <td>2603</td>\n      <td>11</td>\n      <td>2</td>\n      <td>9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>615</td>\n      <td>1</td>\n      <td>2.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.8</td>\n      <td>131</td>\n      <td>6</td>\n      <td>...</td>\n      <td>1216</td>\n      <td>1786</td>\n      <td>2769</td>\n      <td>16</td>\n      <td>8</td>\n      <td>11</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1821</td>\n      <td>1</td>\n      <td>1.2</td>\n      <td>0</td>\n      <td>13</td>\n      <td>1</td>\n      <td>44</td>\n      <td>0.6</td>\n      <td>141</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1208</td>\n      <td>1212</td>\n      <td>1411</td>\n      <td>8</td>\n      <td>2</td>\n      <td>15</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 21 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import dataset from folder  ./data and create a dataframe\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data cleaning + exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape (2000, 21)\n",
      "test shape (1000, 21)\n",
      "train nan values battery_power    0\n",
      "blue             0\n",
      "clock_speed      0\n",
      "dual_sim         0\n",
      "fc               0\n",
      "four_g           0\n",
      "int_memory       0\n",
      "m_dep            0\n",
      "mobile_wt        0\n",
      "n_cores          0\n",
      "pc               0\n",
      "px_height        0\n",
      "px_width         0\n",
      "ram              0\n",
      "sc_h             0\n",
      "sc_w             0\n",
      "talk_time        0\n",
      "three_g          0\n",
      "touch_screen     0\n",
      "wifi             0\n",
      "price_range      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Look for nan values in both train and test\n",
    "print(\"train shape\", train.shape)\n",
    "print(\"test shape\", test.shape)\n",
    "\n",
    "print(\"train nan values\", train.isna().sum())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "No further cleaning is needed, as there are no nan values in the dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Concat test and train dataframe on column number\n",
    "df = pd.concat([train, test], axis=0, sort=False)\n",
    "\n",
    "# Drop coluimn id\n",
    "df.drop('id', axis=1, inplace=True)\n",
    "\n",
    "# Export to pandas dataframe file\n",
    "df.to_csv('../data/dataset_full.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(3000, 21)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correlation matrix\n",
    "With the correlation matrix we can see that the target variable is most correlated with the following features:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "battery_power    0.200723\npx_height        0.148858\npx_width         0.165818\nram              0.917046\nprice_range      1.000000\nName: price_range, dtype: float64"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get correlations of columns in dataset\n",
    "corr = df.corr()\n",
    "# Plot correlations\n",
    "# plt.figure(figsize=(20,20))\n",
    "# sns.heatmap(corr, annot=True, cmap=plt.cm.Reds)\n",
    "# plt.show()\n",
    "# Calculate correlations with target variable\n",
    "cor_target = abs(corr[\"price_range\"])\n",
    "\n",
    "# Select highly correlated features\n",
    "relevant_features = cor_target[(cor_target>0.1) | (cor_target < -0.0)]\n",
    "relevant_features\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply pca to reduce dimensionality with variance 0.95\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(df.drop('price_range', axis=1))\n",
    "pca.n_components_\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m clf \u001B[38;5;241m=\u001B[39m RandomForestClassifier(n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Train the classifier\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[43mclf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mprice_range\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mprice_range\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# get redundant first features\u001B[39;00m\n\u001B[0;32m     11\u001B[0m feature_importances \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(clf\u001B[38;5;241m.\u001B[39mfeature_importances_,\n\u001B[0;32m     12\u001B[0m                                    index \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mdrop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprice_range\u001B[39m\u001B[38;5;124m'\u001B[39m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mcolumns,\n\u001B[0;32m     13\u001B[0m                                     columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimportance\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39msort_values(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimportance\u001B[39m\u001B[38;5;124m'\u001B[39m, ascending\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32m~\\Documents\\FIIT_SS_2022\\NS\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:345\u001B[0m, in \u001B[0;36mBaseForest.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(y):\n\u001B[0;32m    344\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse multilabel-indicator for y is not supported.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 345\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDTYPE\u001B[49m\n\u001B[0;32m    347\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    349\u001B[0m     sample_weight \u001B[38;5;241m=\u001B[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001B[1;32m~\\Documents\\FIIT_SS_2022\\NS\\venv\\lib\\site-packages\\sklearn\\base.py:565\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    563\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[0;32m    564\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 565\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m check_X_y(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[0;32m    566\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[1;32m~\\Documents\\FIIT_SS_2022\\NS\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1122\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1102\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1103\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1104\u001B[0m     )\n\u001B[0;32m   1106\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[0;32m   1107\u001B[0m     X,\n\u001B[0;32m   1108\u001B[0m     accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1119\u001B[0m     input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1120\u001B[0m )\n\u001B[1;32m-> 1122\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[43m_check_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmulti_output\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_numeric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_numeric\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1124\u001B[0m check_consistent_length(X, y)\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m X, y\n",
      "File \u001B[1;32m~\\Documents\\FIIT_SS_2022\\NS\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1132\u001B[0m, in \u001B[0;36m_check_y\u001B[1;34m(y, multi_output, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1130\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001B[39;00m\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m multi_output:\n\u001B[1;32m-> 1132\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1133\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1134\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1135\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1136\u001B[0m \u001B[43m        \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1137\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1138\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43my\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1139\u001B[0m \u001B[43m        \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1140\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1141\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1142\u001B[0m     estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n",
      "File \u001B[1;32m~\\Documents\\FIIT_SS_2022\\NS\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:921\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    915\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    916\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    917\u001B[0m             \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[0;32m    918\u001B[0m         )\n\u001B[0;32m    920\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[1;32m--> 921\u001B[0m         \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    922\u001B[0m \u001B[43m            \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    923\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    924\u001B[0m \u001B[43m            \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    925\u001B[0m \u001B[43m            \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    926\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    928\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_samples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    929\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n",
      "File \u001B[1;32m~\\Documents\\FIIT_SS_2022\\NS\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:161\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[0;32m    145\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[0;32m    146\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[0;32m    147\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    148\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    149\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    159\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    160\u001B[0m     )\n\u001B[1;32m--> 161\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[1;31mValueError\u001B[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "# # Feature Importance: Random Forest\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "#\n",
    "# # Create a random forest classifier\n",
    "# clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "#\n",
    "# # Train the classifier\n",
    "# clf.fit(df.drop('price_range', axis=1), df['price_range'])\n",
    "#\n",
    "# # get redundant first features\n",
    "# feature_importances = pd.DataFrame(clf.feature_importances_,\n",
    "#                                    index = df.drop('price_range', axis=1).columns,\n",
    "#                                     columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data splitting\n",
    "Will be done in separate notebook with training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal distributed columns:  ['price_range']\n",
      "Non normal distributed columns:  ['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g', 'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g', 'touch_screen', 'wifi']\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# assuming your dataframe is called \"df\"\n",
    "norm_cols = []\n",
    "non_norm_cols = []\n",
    "\n",
    "for column in df.columns:\n",
    "    stat, p = shapiro(df[column])\n",
    "    alpha = 0.05\n",
    "    if p > alpha:\n",
    "        norm_cols.append(column)\n",
    "    else:\n",
    "        non_norm_cols.append(column)\n",
    "\n",
    "X_norm = df[norm_cols]\n",
    "X_non_norm = df[non_norm_cols]\n",
    "\n",
    "print(\"Normal distributed columns: \", norm_cols)\n",
    "print(\"Non normal distributed columns: \", non_norm_cols)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
