{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import wandb\n",
    "\n",
    "from config import config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading, scaling the data\n",
    "data has been explored and concaternated in `data_preparerationipynb`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/train.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/mambaforge/envs/ns_a1/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Separate the target variable from the features\n",
    "X = df.drop('price_range', axis=1)\n",
    "\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "y = enc.fit_transform(df['price_range'].values.reshape(-1, 1))\n",
    "\n",
    "#  Split the data into train, validation, and test sets 0.7, 0.15, 0.15\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=config['seed'])\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=config['seed'])\n",
    "\n",
    "# Create scaling pipeline for the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def main():\n",
    "    global model_name\n",
    "    global model_dims\n",
    "    wandb.init(project='phone-price-prediction', name=model_name, config=config)\n",
    "\n",
    "    # Create the data loaders\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train)).batch(wandb.config.batch_size)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).shuffle(len(X_val)).batch(wandb.config.batch_size)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).shuffle(len(X_test)).batch(wandb.config.batch_size)\n",
    "\n",
    "    # Build the model\n",
    "    input_shape = (20,)\n",
    "    input = tf.keras.layers.Dense(20, input_shape=input_shape, activation='relu')\n",
    "    model = tf.keras.Sequential(input)\n",
    "\n",
    "    # Add the hidden layers as specified in the config\n",
    "    if model_dims[0] is not 0:\n",
    "        for size in model_dims:\n",
    "            model.add(tf.keras.layers.Dense(size, activation='relu'))\n",
    "            model.add(tf.keras.layers.Dropout(wandb.config.dropout))\n",
    "\n",
    "    # Add the output layer\n",
    "    output = tf.keras.layers.Dense(4, activation='softmax')\n",
    "    model.add(output)\n",
    "\n",
    "    # Plot the model and log it to wandb\n",
    "    tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, to_file='images/model.png')\n",
    "    wandb.log({'model': wandb.Image('images/model.png')})\n",
    "\n",
    "    # Create optimizer and compile the model\n",
    "    optimizer = tf.keras.optimizers.Adam(beta_1=config['beta1'], beta_2=config['beta2'], epsilon=config['epsilon'], learning_rate=wandb.config.lr)\n",
    "    model.compile(optimizer=optimizer, loss=config['loss_keras'], metrics=['accuracy'])\n",
    "\n",
    "    # Create a callback\n",
    "    wandb_callback = wandb.keras.WandbCallback()\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(train_dataset, epochs=wandb.config.epochs, validation_data=val_dataset, callbacks=[wandb_callback])\n",
    "\n",
    "    # build, compile, and train model here\n",
    "    test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "    # Make a log into the wandb\n",
    "    wandb.log({'test_loss': test_loss, 'test_acc': test_acc})\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "for layer in config['hidden_layers']:\n",
    "\n",
    "    name = 'TensorFlow_' + str(layer)\n",
    "    # Global variables for name and dims workaround\n",
    "    # Not the best solution but works for now :)\n",
    "    global model_name\n",
    "    global model_dims\n",
    "\n",
    "    # Set global for each run of architecture\n",
    "    model_name = name\n",
    "    model_dims = layer\n",
    "    # Sweep for each of the architectures\n",
    "    sweep_id = wandb.sweep(sweep=config, project=\"phone-price-prediction\")\n",
    "    wandb.agent(sweep_id, function=main, count = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
