{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import wandb\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchviz import make_dot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading, scaling the data\n",
    "data has been explored and concaternated in `data_preparerationipynb`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "(2000, 21)"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 20) (300, 20) (300, 20)\n",
      "(1400,) (300,) (300,)\n"
     ]
    }
   ],
   "source": [
    "# Separate the target variable from the features\n",
    "y = df['price_range'].values\n",
    "X = df.drop('price_range', axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "#  Split the data into train, validation, and test sets 0.7, 0.15, 0.15\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class PhoneDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # Convert inputs to torch 32 bit float tensor\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        # One hot encode the labels\n",
    "        self.enc = OneHotEncoder(sparse=False)\n",
    "        y = self.enc.fit_transform(y.reshape(-1, 1))\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < 0 or idx >= len(self):\n",
    "            raise IndexError(f\"Index {idx} is out of range\")\n",
    "\n",
    "        return self.X[idx], self.y[idx]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Forward feed neural network\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=20, out_features=20)\n",
    "        self.fc2 = nn.Linear(in_features=20, out_features=10)\n",
    "        self.fc3 = nn.Linear(in_features=10, out_features=4)\n",
    "\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loss function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "# how to evaluate model with wandb\n",
    "def train(args, model, train_loader, optimizer, criterion):\n",
    "    # Switch model to training mode. This is necessary for layers like dropout, batchnorm etc which behave differently in training and evaluation mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct_train = 0\n",
    "\n",
    "    # We loop over the data iterator, and feed the inputs to the network and adjust the weights.\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Feed the inputs to the network\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        output_category_train = np.argmax(outputs.detach().numpy(), axis=1)\n",
    "        target_category_train = np.argmax(targets.detach().numpy(), axis=1)\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backpropagate the gradient\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct_train += (output_category_train == target_category_train).sum().item()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    accuracy_train = 100. * correct_train / len(train_loader.dataset)\n",
    "    wandb.log({'train_loss': train_loss, 'train_accuracy': accuracy_train})\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "def test(args, model, criterion, test_loader):\n",
    "    # Switch model to evaluation mode. This is necessary for layers like dropout, batchnorm etc which behave differently in training and evaluation mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    example_images = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # Load the input features and labels from the test dataset\n",
    "\n",
    "            output = model(data)\n",
    "            output_category = np.argmax(output, axis=1)\n",
    "            target_category = np.argmax(target, axis=1)\n",
    "            # Compute the loss sum up batch loss\n",
    "            test_loss += criterion(output, target).item()\n",
    "\n",
    "\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct += (output_category == target_category).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        wandb.log({'test_loss': test_loss, 'test_accuracy': accuracy})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.14.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.13.10"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/Users/adam/Documents/NSIETE/ns_a1/code/wandb/run-20230327_162728-msuooo56</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/neural_networks_fiit/phone-price-prediction/runs/msuooo56' target=\"_blank\">olive-fire-120</a></strong> to <a href='https://wandb.ai/neural_networks_fiit/phone-price-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/neural_networks_fiit/phone-price-prediction' target=\"_blank\">https://wandb.ai/neural_networks_fiit/phone-price-prediction</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/neural_networks_fiit/phone-price-prediction/runs/msuooo56' target=\"_blank\">https://wandb.ai/neural_networks_fiit/phone-price-prediction/runs/msuooo56</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/mambaforge/envs/ns_a1/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/adam/mambaforge/envs/ns_a1/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/adam/mambaforge/envs/ns_a1/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.012 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.069223…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28795426072f49b290d5ee34a0bd5806"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▁▂▃▅▆▇▇▇▇██████████████████████████████</td></tr><tr><td>test_loss</td><td>██▇▇▅▄▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▂▂▄▅▆▇▇▇██████████████████████████████</td></tr><tr><td>train_loss</td><td>███▇▅▅▄▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>92.33333</td></tr><tr><td>test_loss</td><td>0.00043</td></tr><tr><td>train_accuracy</td><td>99.57143</td></tr><tr><td>train_loss</td><td>0.00016</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">olive-fire-120</strong> at: <a href='https://wandb.ai/neural_networks_fiit/phone-price-prediction/runs/msuooo56' target=\"_blank\">https://wandb.ai/neural_networks_fiit/phone-price-prediction/runs/msuooo56</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20230327_162728-msuooo56/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"phone-price-prediction\")\n",
    "\n",
    "# Data loader\n",
    "\n",
    "config = wandb.config  # Initialize config\n",
    "\n",
    "config.batch_size = 32          # input batch size for training (default: 64)\n",
    "config.test_batch_size = 64    # input batch size for testing (default: 1000)\n",
    "config.epochs = 50             # number of epochs to train (default: 10)\n",
    "config.lr = 0.001               # learning rate (default: 0.01)\n",
    "config.momentum = 0.1           # SGD momentum (default: 0.5)\n",
    "config.beta1 = 0.9\n",
    "config.beta2 = 0.999\n",
    "config.epsilon = 1e-08\n",
    "config.rho = 0.9\n",
    "# config.no_cuda = True         # disables CUDA training\n",
    "config.seed = 42               # random seed (default: 42)\n",
    "config.log_interval = 10\n",
    "\n",
    "# Create the data loaders\n",
    "train_dataset = PhoneDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = PhoneDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.test_batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = PhoneDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True)\n",
    "\n",
    "device  = torch.device(\"cpu\")\n",
    "kwargs = {}\n",
    "\n",
    "torch.manual_seed(config.seed)\n",
    "\n",
    "model = FFNN().to(device)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=config.momentum)\n",
    "#optimizer = optim.RMSprop(model.parameters(), lr=config.lr, eps=config.epsilon, alpha=config.rho, momentum=config.momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.lr, betas=(config.beta1, config.beta2), eps=config.epsilon)\n",
    "\n",
    "# wandb.watch(model, log=\"all\")\n",
    "\n",
    "for epoch in range(1, config.epochs + 1):\n",
    "    train(config, model, train_loader, optimizer, loss)\n",
    "    test(config, model, loss , val_loader)\n",
    "\n",
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NN Architecture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/mambaforge/envs/ns_a1/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 20]) torch.Size([64, 4])\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 7.1.0 (20230121.1956)\n -->\n<!-- Pages: 1 -->\n<svg width=\"412pt\" height=\"600pt\"\n viewBox=\"0.00 0.00 412.00 600.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 596)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-596 408,-596 408,4 -4,4\"/>\n<!-- 4954719632 -->\n<g id=\"node1\" class=\"node\">\n<title>4954719632</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"227,-31 162,-31 162,0 227,0 227,-31\"/>\n<text text-anchor=\"middle\" x=\"194.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (64, 4)</text>\n</g>\n<!-- 4956305344 -->\n<g id=\"node2\" class=\"node\">\n<title>4956305344</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"251,-86 138,-86 138,-67 251,-67 251,-86\"/>\n<text text-anchor=\"middle\" x=\"194.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">SoftmaxBackward0</text>\n</g>\n<!-- 4956305344&#45;&gt;4954719632 -->\n<g id=\"edge21\" class=\"edge\">\n<title>4956305344&#45;&gt;4954719632</title>\n<path fill=\"none\" stroke=\"black\" d=\"M194.5,-66.54C194.5,-60.07 194.5,-50.98 194.5,-42.32\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"198,-42.58 194.5,-32.58 191,-42.58 198,-42.58\"/>\n</g>\n<!-- 4956305584 -->\n<g id=\"node3\" class=\"node\">\n<title>4956305584</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"245,-141 144,-141 144,-122 245,-122 245,-141\"/>\n<text text-anchor=\"middle\" x=\"194.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 4956305584&#45;&gt;4956305344 -->\n<g id=\"edge1\" class=\"edge\">\n<title>4956305584&#45;&gt;4956305344</title>\n<path fill=\"none\" stroke=\"black\" d=\"M194.5,-121.75C194.5,-115.27 194.5,-106.16 194.5,-97.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"198,-97.96 194.5,-87.96 191,-97.96 198,-97.96\"/>\n</g>\n<!-- 4956298912 -->\n<g id=\"node4\" class=\"node\">\n<title>4956298912</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"129,-196 28,-196 28,-177 129,-177 129,-196\"/>\n<text text-anchor=\"middle\" x=\"78.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 4956298912&#45;&gt;4956305584 -->\n<g id=\"edge2\" class=\"edge\">\n<title>4956298912&#45;&gt;4956305584</title>\n<path fill=\"none\" stroke=\"black\" d=\"M98.18,-176.51C116.45,-168.16 143.91,-155.61 164.85,-146.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"166.1,-149.33 173.74,-141.99 163.19,-142.96 166.1,-149.33\"/>\n</g>\n<!-- 4954734432 -->\n<g id=\"node5\" class=\"node\">\n<title>4954734432</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"111,-262 46,-262 46,-232 111,-232 111,-262\"/>\n<text text-anchor=\"middle\" x=\"78.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\">fc3.bias</text>\n<text text-anchor=\"middle\" x=\"78.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\"> (4)</text>\n</g>\n<!-- 4954734432&#45;&gt;4956298912 -->\n<g id=\"edge3\" class=\"edge\">\n<title>4954734432&#45;&gt;4956298912</title>\n<path fill=\"none\" stroke=\"black\" d=\"M78.5,-231.54C78.5,-224.34 78.5,-215.53 78.5,-207.68\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"82,-207.69 78.5,-197.69 75,-207.69 82,-207.69\"/>\n</g>\n<!-- 4956304240 -->\n<g id=\"node6\" class=\"node\">\n<title>4956304240</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"242,-196 147,-196 147,-177 242,-177 242,-196\"/>\n<text text-anchor=\"middle\" x=\"194.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n</g>\n<!-- 4956304240&#45;&gt;4956305584 -->\n<g id=\"edge4\" class=\"edge\">\n<title>4956304240&#45;&gt;4956305584</title>\n<path fill=\"none\" stroke=\"black\" d=\"M194.5,-176.75C194.5,-170.27 194.5,-161.16 194.5,-152.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"198,-152.96 194.5,-142.96 191,-152.96 198,-152.96\"/>\n</g>\n<!-- 4956300304 -->\n<g id=\"node7\" class=\"node\">\n<title>4956300304</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"237,-256.5 136,-256.5 136,-237.5 237,-237.5 237,-256.5\"/>\n<text text-anchor=\"middle\" x=\"186.5\" y=\"-244.5\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 4956300304&#45;&gt;4956304240 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4956300304&#45;&gt;4956304240</title>\n<path fill=\"none\" stroke=\"black\" d=\"M187.68,-237.37C188.76,-229.5 190.38,-217.6 191.78,-207.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"195.22,-208.05 193.11,-197.67 188.29,-207.1 195.22,-208.05\"/>\n</g>\n<!-- 4956302800 -->\n<g id=\"node8\" class=\"node\">\n<title>4956302800</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-322.5 0,-322.5 0,-303.5 101,-303.5 101,-322.5\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-310.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 4956302800&#45;&gt;4956300304 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4956302800&#45;&gt;4956300304</title>\n<path fill=\"none\" stroke=\"black\" d=\"M69.41,-303.1C92.25,-292.35 130.9,-274.16 157.51,-261.64\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"158.82,-264.89 166.38,-257.47 155.84,-258.56 158.82,-264.89\"/>\n</g>\n<!-- 4954719952 -->\n<g id=\"node9\" class=\"node\">\n<title>4954719952</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"83,-394 18,-394 18,-364 83,-364 83,-394\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-382\" font-family=\"monospace\" font-size=\"10.00\">fc2.bias</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\"> (10)</text>\n</g>\n<!-- 4954719952&#45;&gt;4956302800 -->\n<g id=\"edge7\" class=\"edge\">\n<title>4954719952&#45;&gt;4956302800</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-363.8C50.5,-355.09 50.5,-343.81 50.5,-334.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-334.36 50.5,-324.36 47,-334.36 54,-334.36\"/>\n</g>\n<!-- 4956298768 -->\n<g id=\"node10\" class=\"node\">\n<title>4956298768</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"214,-322.5 119,-322.5 119,-303.5 214,-303.5 214,-322.5\"/>\n<text text-anchor=\"middle\" x=\"166.5\" y=\"-310.5\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n</g>\n<!-- 4956298768&#45;&gt;4956300304 -->\n<g id=\"edge8\" class=\"edge\">\n<title>4956298768&#45;&gt;4956300304</title>\n<path fill=\"none\" stroke=\"black\" d=\"M169.28,-303.1C172.15,-293.93 176.71,-279.34 180.41,-267.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"183.65,-268.86 183.29,-258.27 176.97,-266.77 183.65,-268.86\"/>\n</g>\n<!-- 4956298816 -->\n<g id=\"node11\" class=\"node\">\n<title>4956298816</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"209,-388.5 108,-388.5 108,-369.5 209,-369.5 209,-388.5\"/>\n<text text-anchor=\"middle\" x=\"158.5\" y=\"-376.5\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 4956298816&#45;&gt;4956298768 -->\n<g id=\"edge9\" class=\"edge\">\n<title>4956298816&#45;&gt;4956298768</title>\n<path fill=\"none\" stroke=\"black\" d=\"M159.61,-369.1C160.73,-360.12 162.51,-345.95 163.97,-334.22\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"167.44,-334.68 165.21,-324.33 160.5,-333.81 167.44,-334.68\"/>\n</g>\n<!-- 4956300112 -->\n<g id=\"node12\" class=\"node\">\n<title>4956300112</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"114,-454.5 13,-454.5 13,-435.5 114,-435.5 114,-454.5\"/>\n<text text-anchor=\"middle\" x=\"63.5\" y=\"-442.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 4956300112&#45;&gt;4956298816 -->\n<g id=\"edge10\" class=\"edge\">\n<title>4956300112&#45;&gt;4956298816</title>\n<path fill=\"none\" stroke=\"black\" d=\"M76.71,-435.1C92.02,-424.78 117.52,-407.61 135.98,-395.17\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"137.81,-398.16 144.15,-389.67 133.9,-392.35 137.81,-398.16\"/>\n</g>\n<!-- 4954734112 -->\n<g id=\"node13\" class=\"node\">\n<title>4954734112</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"96,-526 31,-526 31,-496 96,-496 96,-526\"/>\n<text text-anchor=\"middle\" x=\"63.5\" y=\"-514\" font-family=\"monospace\" font-size=\"10.00\">fc1.bias</text>\n<text text-anchor=\"middle\" x=\"63.5\" y=\"-503\" font-family=\"monospace\" font-size=\"10.00\"> (20)</text>\n</g>\n<!-- 4954734112&#45;&gt;4956300112 -->\n<g id=\"edge11\" class=\"edge\">\n<title>4954734112&#45;&gt;4956300112</title>\n<path fill=\"none\" stroke=\"black\" d=\"M63.5,-495.8C63.5,-487.09 63.5,-475.81 63.5,-466.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"67,-466.36 63.5,-456.36 60,-466.36 67,-466.36\"/>\n</g>\n<!-- 4956300064 -->\n<g id=\"node14\" class=\"node\">\n<title>4956300064</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"209,-454.5 132,-454.5 132,-435.5 209,-435.5 209,-454.5\"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-442.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 4956300064&#45;&gt;4956298816 -->\n<g id=\"edge12\" class=\"edge\">\n<title>4956300064&#45;&gt;4956298816</title>\n<path fill=\"none\" stroke=\"black\" d=\"M168.83,-435.1C167.13,-426.03 164.43,-411.64 162.22,-399.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"165.72,-399.49 160.43,-390.31 158.84,-400.78 165.72,-399.49\"/>\n</g>\n<!-- 4956299968 -->\n<g id=\"node15\" class=\"node\">\n<title>4956299968</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"221,-520.5 120,-520.5 120,-501.5 221,-501.5 221,-520.5\"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-508.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 4956299968&#45;&gt;4956300064 -->\n<g id=\"edge13\" class=\"edge\">\n<title>4956299968&#45;&gt;4956300064</title>\n<path fill=\"none\" stroke=\"black\" d=\"M170.5,-501.1C170.5,-492.12 170.5,-477.95 170.5,-466.22\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"174,-466.34 170.5,-456.34 167,-466.34 174,-466.34\"/>\n</g>\n<!-- 4954731552 -->\n<g id=\"node16\" class=\"node\">\n<title>4954731552</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"209,-592 132,-592 132,-562 209,-562 209,-592\"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-580\" font-family=\"monospace\" font-size=\"10.00\">fc1.weight</text>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-569\" font-family=\"monospace\" font-size=\"10.00\"> (20, 20)</text>\n</g>\n<!-- 4954731552&#45;&gt;4956299968 -->\n<g id=\"edge14\" class=\"edge\">\n<title>4954731552&#45;&gt;4956299968</title>\n<path fill=\"none\" stroke=\"black\" d=\"M170.5,-561.8C170.5,-553.09 170.5,-541.81 170.5,-532.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"174,-532.36 170.5,-522.36 167,-532.36 174,-532.36\"/>\n</g>\n<!-- 4956295888 -->\n<g id=\"node17\" class=\"node\">\n<title>4956295888</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"309,-322.5 232,-322.5 232,-303.5 309,-303.5 309,-322.5\"/>\n<text text-anchor=\"middle\" x=\"270.5\" y=\"-310.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 4956295888&#45;&gt;4956300304 -->\n<g id=\"edge15\" class=\"edge\">\n<title>4956295888&#45;&gt;4956300304</title>\n<path fill=\"none\" stroke=\"black\" d=\"M258.82,-303.1C245.4,-292.88 223.15,-275.93 206.87,-263.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"209.36,-261.02 199.28,-257.74 205.12,-266.59 209.36,-261.02\"/>\n</g>\n<!-- 4956299776 -->\n<g id=\"node18\" class=\"node\">\n<title>4956299776</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"328,-388.5 227,-388.5 227,-369.5 328,-369.5 328,-388.5\"/>\n<text text-anchor=\"middle\" x=\"277.5\" y=\"-376.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 4956299776&#45;&gt;4956295888 -->\n<g id=\"edge16\" class=\"edge\">\n<title>4956299776&#45;&gt;4956295888</title>\n<path fill=\"none\" stroke=\"black\" d=\"M276.53,-369.1C275.54,-360.12 273.99,-345.95 272.71,-334.22\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"276.2,-333.89 271.63,-324.33 269.24,-334.65 276.2,-333.89\"/>\n</g>\n<!-- 4954731472 -->\n<g id=\"node19\" class=\"node\">\n<title>4954731472</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"316,-460 239,-460 239,-430 316,-430 316,-460\"/>\n<text text-anchor=\"middle\" x=\"277.5\" y=\"-448\" font-family=\"monospace\" font-size=\"10.00\">fc2.weight</text>\n<text text-anchor=\"middle\" x=\"277.5\" y=\"-437\" font-family=\"monospace\" font-size=\"10.00\"> (10, 20)</text>\n</g>\n<!-- 4954731472&#45;&gt;4956299776 -->\n<g id=\"edge17\" class=\"edge\">\n<title>4954731472&#45;&gt;4956299776</title>\n<path fill=\"none\" stroke=\"black\" d=\"M277.5,-429.8C277.5,-421.09 277.5,-409.81 277.5,-400.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"281,-400.36 277.5,-390.36 274,-400.36 281,-400.36\"/>\n</g>\n<!-- 4956302128 -->\n<g id=\"node20\" class=\"node\">\n<title>4956302128</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"360,-196 283,-196 283,-177 360,-177 360,-196\"/>\n<text text-anchor=\"middle\" x=\"321.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 4956302128&#45;&gt;4956305584 -->\n<g id=\"edge18\" class=\"edge\">\n<title>4956302128&#45;&gt;4956305584</title>\n<path fill=\"none\" stroke=\"black\" d=\"M299.96,-176.51C279.76,-168.08 249.33,-155.38 226.34,-145.79\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"227.7,-142.56 217.12,-141.94 225,-149.02 227.7,-142.56\"/>\n</g>\n<!-- 4956300016 -->\n<g id=\"node21\" class=\"node\">\n<title>4956300016</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"396,-256.5 295,-256.5 295,-237.5 396,-237.5 396,-256.5\"/>\n<text text-anchor=\"middle\" x=\"345.5\" y=\"-244.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 4956300016&#45;&gt;4956302128 -->\n<g id=\"edge19\" class=\"edge\">\n<title>4956300016&#45;&gt;4956302128</title>\n<path fill=\"none\" stroke=\"black\" d=\"M341.96,-237.37C338.66,-229.33 333.63,-217.07 329.38,-206.72\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"332.66,-205.49 325.63,-197.57 326.19,-208.15 332.66,-205.49\"/>\n</g>\n<!-- 4954732272 -->\n<g id=\"node22\" class=\"node\">\n<title>4954732272</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"404,-328 327,-328 327,-298 404,-298 404,-328\"/>\n<text text-anchor=\"middle\" x=\"365.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\">fc3.weight</text>\n<text text-anchor=\"middle\" x=\"365.5\" y=\"-305\" font-family=\"monospace\" font-size=\"10.00\"> (4, 10)</text>\n</g>\n<!-- 4954732272&#45;&gt;4956300016 -->\n<g id=\"edge20\" class=\"edge\">\n<title>4954732272&#45;&gt;4956300016</title>\n<path fill=\"none\" stroke=\"black\" d=\"M361.06,-297.8C358.28,-288.89 354.66,-277.3 351.61,-267.54\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"355.04,-266.79 348.72,-258.29 348.36,-268.88 355.04,-266.79\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": "<graphviz.graphs.Digraph at 0x1276b37f0>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = PhoneDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Get one batch of training data\n",
    "X, y = next(iter(train_loader))\n",
    "print(X.shape, y.shape)\n",
    "model = FFNN()\n",
    "y = model(X)\n",
    "\n",
    "y = model(X)\n",
    "make_dot(y, params=dict(model.named_parameters()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
